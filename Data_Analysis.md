**Link to Data Resposne:** https://sydneyinstitute-my.sharepoint.com/:x:/g/personal/s20250004_sihe_edu_au/Efx4xwBuDxJChOYV34NIh3cBw30__eVGMqS3L2h9oMCoMg?e=8IUyfu
# Survey Analysis: AI/ML Tools for Cybersecurity in Hospitals

---

## 1. Current Role

| Role                                   | Count | Percentage |
|----------------------------------------|-------|------------|
| Other IT Staff                         | 42    | 42%        |
| Cybersecurity Analyst or Engineer      | 30    | 30%        |
| IT/Cybersecurity Manager               | 18    | 18%        |
| Chief Information Security Officer (CISO) | 10 | 10%        |

**Current Role of Participants:**  
The survey questionnaires reached out to a wide body of IT and security personnel in the healthcare industry. The greatest percentage is with the "Other IT Staff" (42%), which is a significant presence of both frontline technical support and network administrators. Almost half of the respondents (48%) are cybersecurity professionals (Analyst/Engineer and Manager), giving analytical insight into the security practices. The CISOs representation present in the advisory group will be 10 percent and will provide a strategic and financial insight.

---

## 2. Does your hospital currently use dedicated AI/ML tools for cybersecurity?

| Response                          | Count | Percentage |
|-----------------------------------|-------|------------|
| No                                | 38    | 38%        |
| We are currently implementing them | 27   | 27%        |
| I don't know                      | 20    | 20%        |
| Yes                               | 15    | 15%        |

**Current Use of AI/ML Tools:**  
The market adoption can only indicate how an industry is on a transition. Almost a third of the segment (38%) indicates that they do not utilize AI tools, which shows that their usage is not widespread yet. But the high (27%) implementing them today shows an increasing and high trend towards the adoption. There is a surprising proportion of 20 percent who do not know whether the organization has implemented AI, and it is possible that this reflects poor levels of communication or that AI has only been deployed internally by specialist teams.

---

## 3. How effective is AI at detecting phishing emails compared to older methods?

| Response              | Count | Percentage |
|-----------------------|-------|------------|
| More Effective        | 45    | 45%        |
| Much More Effective   | 19    | 19%        |
| About the Same        | 18    | 18%        |
| Less Effective        | 11    | 11%        |
| Much Less Effective   | 7     | 7%         |

**Effectiveness in Detecting Phishing:**  
The general attitude towards the effectiveness of AI is quite positive but not everyone believes it. A combined 74% agree that AI tools are more/much more effective against this threat compared to familiar methods, positive indicators that the industry feels confident in its effectiveness (against this threat). Nonetheless, on a combined scale of 18%, it is less effective, meaning that it matters how and with what mean the implementation is done, or what particular environmental inputs apply.

---

## 4. Do you believe that AI's automatic defenses are fast enough to stop ransomware?

| Response                     | Count | Percentage |
|------------------------------|-------|------------|
| Agree                        | 61    | 61%        |
| Neither Agree nor Disagree   | 30    | 30%        |
| Disagree                     | 7     | 7%         |
| Strongly Disagree            | 2     | 2%         |

**Speed Against Ransomware:**  
There is a reserved optimism on the pace of ransomware fought by using AI. Majority of people (61%) also believe the defense systems of AI are fast enough, which indicates their expectation of an automated reaction time. Nonetheless, a large neutral segment (30) means that there is much uncertainty or there is a lack of direct involvement in having a certain opinion. What it means is that although the possibilities are known and proven feasible, there is a lack of documented, actual-world success against a rapidly evolving threat, like ransomware.

---

## 5. What's the biggest challenge in adopting AI security tools?

| Challenge                            | Count | Percentage |
|--------------------------------------|-------|------------|
| The high cost                        | 38    | 38%        |
| Problems with existing systems       | 30    | 30%        |
| Lack of skilled staff                | 17    | 17%        |
| Worry about disrupting hospital work | 15    | 15%        |

**Biggest Adoption Challenge:**  
The main adopting resistance factors are evident money and technical factors. High cost (38%) constitutes the most significant factor that deter small hospitals because it presents an obstacle. The legacy of an obsolete system, or what I would term as the "problems of existing systems" (30%), is a formidable challenge as it implies the integration with previously established healthcare systems and the specialized medical internet of things devices that are prevalent in the field.

---

## 6. Which AI security alert is the most urgent?

| Alert                        | Count | Percentage |
|------------------------------|-------|------------|
| Phishing attempt detected    | 44    | 44%        |
| Ransomware activity suspected| 32    | 32%        |
| Network intrusion alert      | 19    | 19%        |
| Suspicious user login        | 5     | 5%         |

**Most Urgent Security Alert:**  
The ranking of alerts reveals what professionals perceive as the most critical threats. "Phishing attempt detected" (44%) is deemed the most urgent, as phishing is the primary vector for initial network access. The high priority of "Ransomware activity suspected" (32%) underscores the extreme damage this attack can cause in a healthcare setting, where patient care is directly at risk.

---

## 7. Do you think AI security tools can save your team time on investigations?

| Response                | Count | Percentage |
|-------------------------|-------|------------|
| Yes, a little time      | 55    | 55%        |
| Yes, a lot of time      | 23    | 23%        |
| No, it's about the same | 18    | 18%        |
| No, they create more work| 4    | 4%         |

**Impact on Investigation Time:**  
AI is largely seen as a net positive for operational efficiency. A majority of respondents (78%) report that AI saves time, validating one of its key value propositions. However, the fact that most only save "a little time" (55%) indicates that time savings are often offset by new tasks, such as investigating false positives. A minority (22%) report no savings or even more work, often due to poorly tuned systems generating excessive alerts.

---

## 8. Biggest Improvement or Gap (Thematic Analysis)

This was an open-ended question, so responses are grouped by common themes. Many respondents left this blank.

| Theme                                                                  | Approx. Count* |
|------------------------------------------------------------------------|----------------|
| Cost & Resource Concerns (High cost, unaffordable for smaller hospitals)| 12             |
| Explainability & Transparency ("Black box" AI, need for reasoning)     | 7              |
| Integration & Technical Challenges (Legacy systems, medical IoT devices)| 6              |
| False Positives & Disruption (Risks to patient care, workflow disruption)| 5             |
| Efficiency & Effectiveness (Saves time, reduces fatigue, finds patterns)| 4             |
| Human Factor & Trust (Need for human oversight, lack of trust in AI)   | 4              |
| No response / Blank                                                    | 62             |

**Biggest Improvement or Gap:**  
The free-text responses emerge with profound, complex issues related to the implementation in the real world. The frequent need to have Explainable AI (XAI) shows an important gap in trust; professionals require to understand why an alert has occurred so that they can act appropriately and justify their actions. Financial implications are not only seen in the form of upfront cost but also in its maintenance subscriptions and workforce; making it uneven between large and small hospitals. Lastly, the possibility of AI concerning critical patient care workflows with false positives and the near-impossibility of securing legacy systems, is a primary concern with the unique healthcare setting.

